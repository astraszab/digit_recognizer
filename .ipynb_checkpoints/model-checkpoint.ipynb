{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mnist import MNIST\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from MNIST dataset\n",
    "\n",
    "mndata = MNIST('data')\n",
    "\n",
    "X_train, y_train_orig = [np.array(ls) for ls in mndata.load_training()]\n",
    "X_test, y_test_orig = [np.array(ls) for ls in mndata.load_testing()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is: (60000, 784)\n",
      "y_train shape is: (60000,)\n",
      "X_test shape is: (10000, 784)\n",
      "y_test shape is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Original data shapes\n",
    "print('X_train shape is: {}'.format(X_train.shape))\n",
    "print('y_train shape is: {}'.format(y_train_orig.shape))\n",
    "print('X_test shape is: {}'.format(X_test.shape))\n",
    "print('y_test shape is: {}'.format(y_test_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = np.sqrt(X_train.shape[1]).astype(int)\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data\n",
    "X_train = np.reshape(X_train, newshape=(train_size, img_width, img_width, num_channels))\n",
    "X_test = np.reshape(X_test, newshape=(test_size, img_width, img_width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55d01289b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of an image\n",
    "i = 7\n",
    "\n",
    "print('Label: {}'.format(y_train_orig[i]))\n",
    "plt.imshow(X_train[i, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing input\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train_orig, num_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test_orig, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is: (60000, 28, 28, 1)\n",
      "Y_train shape is: (60000, 10)\n",
      "X_test shape is: (10000, 28, 28, 1)\n",
      "Y_test shape is: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Data shapes after preprocessing\n",
    "print('X_train shape is: {}'.format(X_train.shape))\n",
    "print('Y_train shape is: {}'.format(Y_train.shape))\n",
    "print('X_test shape is: {}'.format(X_test.shape))\n",
    "print('Y_test shape is: {}'.format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_width, num_channels, num_classes):\n",
    "    '''Builds CNN model'''\n",
    "    X_input = Input(batch_shape=(None, img_width, img_width, num_channels))\n",
    "    X = Conv2D(32, kernel_size=(3, 3), activation='relu')(X_input)\n",
    "    X = Conv2D(64, kernel_size=(3, 3), activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    Y = Dense(num_classes, activation='softmax')(X)\n",
    "    model = Model(X_input, Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/uladzislaw/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/uladzislaw/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Building a model\n",
    "\n",
    "model = build_model(img_width, num_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a model\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/uladzislaw/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 45s 747us/step - loss: 0.2621 - acc: 0.9191 - val_loss: 0.0618 - val_acc: 0.9807\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 46s 766us/step - loss: 0.0860 - acc: 0.9744 - val_loss: 0.0381 - val_acc: 0.9871\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 50s 826us/step - loss: 0.0655 - acc: 0.9809 - val_loss: 0.0356 - val_acc: 0.9868\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.0535 - acc: 0.9837 - val_loss: 0.0315 - val_acc: 0.9898\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 48s 796us/step - loss: 0.0452 - acc: 0.9864 - val_loss: 0.0346 - val_acc: 0.9888\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 47s 791us/step - loss: 0.0399 - acc: 0.9881 - val_loss: 0.0274 - val_acc: 0.9899\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 46s 767us/step - loss: 0.0359 - acc: 0.9890 - val_loss: 0.0259 - val_acc: 0.9911\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 48s 798us/step - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0273 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 53s 876us/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0243 - val_acc: 0.9919\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 50s 827us/step - loss: 0.0284 - acc: 0.9913 - val_loss: 0.0242 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 49s 817us/step - loss: 0.0272 - acc: 0.9917 - val_loss: 0.0263 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 53s 887us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0233 - val_acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55cf6f8a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a model\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.023343717768202987\n",
      "Test accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "# Evaluating a model\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a model\n",
    "\n",
    "model.save('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a model\n",
    "\n",
    "plot_model(model, to_file='mnist_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
